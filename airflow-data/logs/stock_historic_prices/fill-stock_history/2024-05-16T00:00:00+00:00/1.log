[2024-05-17 23:31:45,922] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: stock_historic_prices.fill-stock_history 2024-05-16T00:00:00+00:00 [queued]>
[2024-05-17 23:31:45,940] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: stock_historic_prices.fill-stock_history 2024-05-16T00:00:00+00:00 [queued]>
[2024-05-17 23:31:45,942] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2024-05-17 23:31:45,943] {taskinstance.py:1018} INFO - Starting attempt 1 of 2
[2024-05-17 23:31:45,944] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2024-05-17 23:31:45,954] {taskinstance.py:1038} INFO - Executing <Task(PythonOperator): fill-stock_history> on 2024-05-16T00:00:00+00:00
[2024-05-17 23:31:45,960] {standard_task_runner.py:51} INFO - Started process 810 to run task
[2024-05-17 23:31:45,965] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'stock_historic_prices', 'fill-stock_history', '2024-05-16T00:00:00+00:00', '--job-id', '4', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/stock_historic_prices.py', '--cfg-path', '/tmp/tmpdn_xk2rb']
[2024-05-17 23:31:45,971] {standard_task_runner.py:76} INFO - Job 4: Subtask fill-stock_history
[2024-05-17 23:31:46,026] {logging_mixin.py:103} INFO - Running <TaskInstance: stock_historic_prices.fill-stock_history 2024-05-16T00:00:00+00:00 [running]> on host 6b6a50b197a8
[2024-05-17 23:31:46,093] {taskinstance.py:1232} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=stock_historic_prices
AIRFLOW_CTX_TASK_ID=fill-stock_history
AIRFLOW_CTX_EXECUTION_DATE=2024-05-16T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-05-16T00:00:00+00:00
[2024-05-17 23:31:46,101] {logging_mixin.py:103} INFO - Conexión exitosa a PostgreSQL
[2024-05-17 23:32:11,436] {local_task_job.py:170} WARNING - State of this instance has been externally set to success. Terminating instance.
[2024-05-17 23:32:11,459] {process_utils.py:95} INFO - Sending Signals.SIGTERM to GPID 810
[2024-05-17 23:32:29,236] {taskinstance.py:1214} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-05-17 23:32:29,793] {logging_mixin.py:103} INFO - Error al ejecutar la consulta de insert: Task received SIGTERM signal
[2024-05-17 23:32:30,134] {logging_mixin.py:103} INFO - Desconexión exitosa de PostgreSQL
[2024-05-17 23:32:30,641] {python.py:118} INFO - Done. Returned value was: None
[2024-05-17 23:32:30,681] {taskinstance.py:1396} ERROR - (psycopg2.OperationalError) FATAL:  the database system is in recovery mode

(Background on this error at: http://sqlalche.me/e/13/e3q8)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 241, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/psycopg2/__init__.py", line 127, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: FATAL:  the database system is in recovery mode


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1087, in _run_raw_task
    self.refresh_from_db(lock_for_update=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 65, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 554, in refresh_from_db
    ti = qry.with_for_update().first()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3429, in first
    ret = list(self[0:1])
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3203, in __getitem__
    return list(res)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3557, in _execute_and_instances
    querycontext, self._connection_from_session, close_with_result=True
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3572, in _get_bind_args
    mapper=self._bind_mapper(), clause=querycontext.statement, **kw
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3550, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1145, in connection
    execution_options=execution_options,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1151, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 433, in _connection_for_bind
    conn = bind._contextual_connect()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2340, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1584, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 241, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/psycopg2/__init__.py", line 127, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  the database system is in recovery mode

(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2024-05-17 23:32:30,764] {taskinstance.py:1440} INFO - Marking task as UP_FOR_RETRY. dag_id=stock_historic_prices, task_id=fill-stock_history, execution_date=20240516T000000, start_date=20240517T233145, end_date=20240517T233230
[2024-05-17 23:32:30,931] {process_utils.py:61} INFO - Process psutil.Process(pid=810, status='terminated', exitcode=1, started='23:31:45') (810) terminated with exit code 1
[2024-05-17 23:32:30,944] {local_task_job.py:118} INFO - Task exited with return code 1
[2024-05-18 00:20:23,795] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: stock_historic_prices.fill-stock_history 2024-05-16T00:00:00+00:00 [queued]>
[2024-05-18 00:20:23,818] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: stock_historic_prices.fill-stock_history 2024-05-16T00:00:00+00:00 [queued]>
[2024-05-18 00:20:23,823] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2024-05-18 00:20:23,824] {taskinstance.py:1018} INFO - Starting attempt 1 of 2
[2024-05-18 00:20:23,825] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2024-05-18 00:20:23,856] {taskinstance.py:1038} INFO - Executing <Task(PythonOperator): fill-stock_history> on 2024-05-16T00:00:00+00:00
[2024-05-18 00:20:23,864] {standard_task_runner.py:51} INFO - Started process 763 to run task
[2024-05-18 00:20:23,872] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'stock_historic_prices', 'fill-stock_history', '2024-05-16T00:00:00+00:00', '--job-id', '5', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/stock_historic_prices.py', '--cfg-path', '/tmp/tmp9gjyysxa']
[2024-05-18 00:20:23,881] {standard_task_runner.py:76} INFO - Job 5: Subtask fill-stock_history
[2024-05-18 00:20:23,987] {logging_mixin.py:103} INFO - Running <TaskInstance: stock_historic_prices.fill-stock_history 2024-05-16T00:00:00+00:00 [running]> on host 4367f4ce7644
[2024-05-18 00:20:24,078] {taskinstance.py:1232} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=stock_historic_prices
AIRFLOW_CTX_TASK_ID=fill-stock_history
AIRFLOW_CTX_EXECUTION_DATE=2024-05-16T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-05-16T00:00:00+00:00
[2024-05-18 00:20:24,091] {logging_mixin.py:103} INFO - Conexión exitosa a PostgreSQL
[2024-05-18 00:20:39,167] {local_task_job.py:170} WARNING - State of this instance has been externally set to success. Terminating instance.
[2024-05-18 00:20:39,180] {process_utils.py:95} INFO - Sending Signals.SIGTERM to GPID 763
[2024-05-18 00:20:39,182] {taskinstance.py:1214} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-05-18 00:20:39,273] {logging_mixin.py:103} INFO - Error al ejecutar la consulta de insert: Task received SIGTERM signal
[2024-05-18 00:20:39,281] {logging_mixin.py:103} INFO - Desconexión exitosa de PostgreSQL
[2024-05-18 00:20:39,935] {python.py:118} INFO - Done. Returned value was: None
[2024-05-18 00:20:39,954] {taskinstance.py:1142} INFO - Marking task as SUCCESS. dag_id=stock_historic_prices, task_id=fill-stock_history, execution_date=20240516T000000, start_date=20240518T002023, end_date=20240518T002039
[2024-05-18 00:20:40,000] {taskinstance.py:1195} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-18 00:20:40,043] {process_utils.py:61} INFO - Process psutil.Process(pid=763, status='terminated', exitcode=0, started='00:20:23') (763) terminated with exit code 0
[2024-05-18 00:20:40,046] {local_task_job.py:118} INFO - Task exited with return code 0
